{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I: Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11bb51370>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define constants\n",
    "EMBEDDING_DIM = 16\n",
    "HIDDEN_DIM = 16\n",
    "LATENT_DIM = 16 # Dimension of the latent space\n",
    "SEQ_LEN = 16 # Max length of the sequence\n",
    "# D_MODEL = 64 # Dimension of the model\n",
    "# NHEAD = 16 # Number of attention heads\n",
    "# NUM_ENCODER_LAYERS = 16 # Number of encoder layers\n",
    "# NUM_DECODER_LAYERS = 16 # Number of decoder layers\n",
    "# DIM_FEEDFORWARD = 64 # Dimension of the feedforward network model\n",
    "\n",
    "# Gumbel softmax temperature\n",
    "TAU = 1.0\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device('mps')\n",
    "torch.random.manual_seed(1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the Transformer-based CVAE model\n",
    "# class TransformerEncoder(nn.Module):\n",
    "#     def __init__(self, d_model=EMBEDDING_DIM, nhead=4, num_layers=2):\n",
    "#         super(TransformerEncoder, self).__init__()\n",
    "#         self.embedding = nn.Embedding(VOCAB_SIZE, d_model)\n",
    "#         self.transformer_encoder = nn.TransformerEncoder(\n",
    "#             nn.TransformerEncoderLayer(d_model, nhead), num_layers\n",
    "#         )\n",
    "#         self.fc_logits = nn.Linear(d_model, LATENT_DIM)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         embedded = self.embedding(x).permute(1, 0, 2)  # Transformer expects seq_len, batch, features\n",
    "#         transformed = self.transformer_encoder(embedded)\n",
    "#         # Use the final state to predict logits for latent space\n",
    "#         logits = self.fc_logits(transformed[-1])\n",
    "#         return logits\n",
    "\n",
    "\n",
    "# class TransformerDecoder(nn.Module):\n",
    "#     def __init__(self, d_model=EMBEDDING_DIM, nhead=4, num_layers=2):\n",
    "#         super(TransformerDecoder, self).__init__()\n",
    "#         self.embedding = nn.Embedding(VOCAB_SIZE, d_model)\n",
    "#         self.transformer_decoder = nn.TransformerDecoder(\n",
    "#             nn.TransformerDecoderLayer(d_model, nhead), num_layers\n",
    "#         )\n",
    "#         self.fc_out = nn.Linear(d_model, VOCAB_SIZE)\n",
    "#         self.fc_z = nn.Linear(LATENT_DIM, d_model)  # Convert z to feature size for transformer\n",
    "\n",
    "#     def forward(self, x, z):\n",
    "#         embedded = self.embedding(x).permute(1, 0, 2) # Transformer expects [seq_len, batch, features], permute函数用于改变张量的维度顺序\n",
    "#         z_adjusted = self.fc_z(z).unsqueeze(0)\n",
    "#         output = self.transformer_decoder(embedded, z_adjusted)\n",
    "#         return self.fc_out(output.permute(1, 0, 2))\n",
    "\n",
    "\n",
    "# class TransformerCVAE(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(TransformerCVAE, self).__init__()\n",
    "#         self.encoder = TransformerEncoder()\n",
    "#         self.decoder = TransformerDecoder()\n",
    "\n",
    "#     def reparameterize(self, logits):\n",
    "#         return F.gumbel_softmax(logits, tau=TAU, hard=False, dim=-1)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         logits = self.encoder(x)\n",
    "#         z = self.reparameterize(logits)\n",
    "#         return self.decoder(x, z), logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass embeded into decoder instead of using the original x\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, d_model=EMBEDDING_DIM, nhead=4, num_layers=2):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(VOCAB_SIZE, d_model)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model, nhead), num_layers\n",
    "        )\n",
    "        self.fc_logits = nn.Linear(d_model, LATENT_DIM)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x).permute(1, 0, 2)  # Transformer expects seq_len, batch, features\n",
    "        transformed = self.transformer_encoder(embedded)\n",
    "        # Use the final state to predict logits for latent space\n",
    "        logits = self.fc_logits(transformed[-1])\n",
    "        return logits, embedded\n",
    "\n",
    "\n",
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, d_model=EMBEDDING_DIM, nhead=4, num_layers=2):\n",
    "        super(TransformerDecoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(VOCAB_SIZE, d_model)\n",
    "        self.transformer_decoder = nn.TransformerDecoder(\n",
    "            nn.TransformerDecoderLayer(d_model, nhead), num_layers\n",
    "        )\n",
    "        self.fc_out = nn.Linear(d_model, VOCAB_SIZE)\n",
    "        self.fc_z = nn.Linear(LATENT_DIM, d_model)  # Convert z to feature size for transformer\n",
    "\n",
    "    def forward(self, embedded, z):\n",
    "        # embedded = self.embedding(x).permute(1, 0, 2) # Transformer expects [seq_len, batch, features], permute函数用于改变张量的维度顺序\n",
    "        z_adjusted = self.fc_z(z).unsqueeze(0)\n",
    "        output = self.transformer_decoder(embedded, z_adjusted)\n",
    "        return self.fc_out(output.permute(1, 0, 2))\n",
    "\n",
    "\n",
    "class TransformerCVAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TransformerCVAE, self).__init__()\n",
    "        self.encoder = TransformerEncoder()\n",
    "        self.decoder = TransformerDecoder()\n",
    "\n",
    "    def reparameterize(self, logits):\n",
    "        return F.gumbel_softmax(logits, tau=TAU, hard=False, dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits, emb = self.encoder(x)\n",
    "        z = self.reparameterize(logits)\n",
    "        return self.decoder(emb, z), logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TransformerCVAE\n",
    "\n",
    "# class TransformerEncoder(nn.Module):\n",
    "#     def __init__(self, vocab_size, d_model, nhead, num_encoder_layers, dim_feedforward):\n",
    "#         super(TransformerEncoder, self).__init__()\n",
    "#         self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "#         self.transformer_encoder = nn.TransformerEncoder(\n",
    "#             encoder_layer=nn.TransformerEncoderLayer(d_model, nhead, dim_feedforward),\n",
    "#             num_layers=num_encoder_layers\n",
    "#         )\n",
    "#         self.fc_out = nn.Linear(d_model, d_model * 2)  # 2 for mean and log variance\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         embedded = self.embedding(x).permute(1, 0, 2)\n",
    "#         output = self.transformer_encoder(embedded)\n",
    "#         return self.fc_out(output[0])\n",
    "\n",
    "# class TransformerDecoder(nn.Module):\n",
    "#     def __init__(self, vocab_size, d_model, nhead, num_decoder_layers, dim_feedforward):\n",
    "#         super(TransformerDecoder, self).__init__()\n",
    "#         self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "#         self.transformer_decoder = nn.TransformerDecoder(\n",
    "#             decoder_layer=nn.TransformerDecoderLayer(d_model, nhead, dim_feedforward),\n",
    "#             num_layers=num_decoder_layers\n",
    "#         )\n",
    "#         self.fc_out = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "#     def forward(self, z, max_len=SEQ_LEN):\n",
    "#         # 为变压器解码器创建一个虚拟输入，所有索引都设置为PAD token\n",
    "#         input_tensor = torch.full((max_len, z.size(0)), word_index[PAD_TOKEN], dtype=torch.long).to(z.device)\n",
    "#         input_tensor[0, :] = word_index[UNK_TOKEN]  # 为所有批次设置第一个令牌为UNK\n",
    "#         embedded = self.embedding(input_tensor).permute(1, 0, 2)\n",
    "        \n",
    "#         # 确保z具有正确的形状\n",
    "#         z_expanded = z.unsqueeze(1).repeat(1, SEQ_LEN, 1)\n",
    "\n",
    "#         output = self.transformer_decoder(embedded, z_expanded)\n",
    "#         return self.fc_out(output.permute(1, 0, 2))\n",
    "\n",
    "# class TransformerCVAE(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(TransformerCVAE, self).__init__()\n",
    "#         self.encoder = TransformerEncoder(VOCAB_SIZE, D_MODEL, NHEAD, NUM_ENCODER_LAYERS, DIM_FEEDFORWARD)\n",
    "#         self.decoder = TransformerDecoder(VOCAB_SIZE, D_MODEL, NHEAD, NUM_DECODER_LAYERS, DIM_FEEDFORWARD)\n",
    "\n",
    "#     def reparameterize(self, logits):\n",
    "#         mean, logvar = torch.chunk(logits, 2, dim=-1)\n",
    "#         std = torch.exp(0.5 * logvar)\n",
    "#         eps = torch.randn_like(std)\n",
    "#         return mean + eps * std\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         logits = self.encoder(x)\n",
    "#         z = self.reparameterize(logits)\n",
    "#         return self.decoder(z), logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TransformerEncoder(nn.Module):\n",
    "#     def __init__(self, vocab_size, d_model, nhead, num_encoder_layers, dim_feedforward):\n",
    "#         super(TransformerEncoder, self).__init__()\n",
    "#         self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "#         self.transformer_encoder = nn.TransformerEncoder(\n",
    "#             encoder_layer=nn.TransformerEncoderLayer(d_model, nhead, dim_feedforward),\n",
    "#             num_layers=num_encoder_layers\n",
    "#         )\n",
    "#         self.fc_out = nn.Linear(d_model, d_model * 2)  # 2 for mean and log variance\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         embedded = self.embedding(x).permute(1, 0, 2)\n",
    "#         output = self.transformer_encoder(embedded)\n",
    "        \n",
    "#         # 使用整个序列的平均值\n",
    "#         output_mean = output.mean(dim=0)\n",
    "#         return self.fc_out(output_mean)\n",
    "\n",
    "# class TransformerDecoder(nn.Module):\n",
    "#     def __init__(self, vocab_size, d_model, nhead, num_decoder_layers, dim_feedforward):\n",
    "#         super(TransformerDecoder, self).__init__()\n",
    "#         self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "#         self.transformer_decoder = nn.TransformerDecoder(\n",
    "#             decoder_layer=nn.TransformerDecoderLayer(d_model, nhead, dim_feedforward),\n",
    "#             num_layers=num_decoder_layers\n",
    "#         )\n",
    "#         self.fc_out = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "#     def forward(self, z, max_len=SEQ_LEN):\n",
    "#         # 使用 <SOS> 令牌作为解码器的输入开始\n",
    "#         input_tensor = torch.full((max_len, z.size(0)), word_index[PAD_TOKEN], dtype=torch.long).to(z.device)\n",
    "#         input_tensor[0, :] = word_index[SOS_TOKEN]\n",
    "        \n",
    "#         embedded = self.embedding(input_tensor).permute(1, 0, 2)\n",
    "        \n",
    "#         # 确保z具有正确的形状\n",
    "#         z_expanded = z.unsqueeze(1).repeat(1, max_len, 1)\n",
    "\n",
    "#         output = self.transformer_decoder(embedded, z_expanded)\n",
    "#         return self.fc_out(output.permute(1, 0, 2))\n",
    "        \n",
    "# class TransformerCVAE(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(TransformerCVAE, self).__init__()\n",
    "#         self.encoder = TransformerEncoder(VOCAB_SIZE, D_MODEL, NHEAD, NUM_ENCODER_LAYERS, DIM_FEEDFORWARD)\n",
    "#         self.decoder = TransformerDecoder(VOCAB_SIZE, D_MODEL, NHEAD, NUM_DECODER_LAYERS, DIM_FEEDFORWARD)\n",
    "\n",
    "#     def reparameterize(self, logits):\n",
    "#         mean, logvar = torch.chunk(logits, 2, dim=-1)\n",
    "#         std = torch.exp(0.5 * logvar)\n",
    "#         eps = torch.randn_like(std)\n",
    "#         return mean + eps * std\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         logits = self.encoder(x)\n",
    "#         z = self.reparameterize(logits)\n",
    "#         return self.decoder(z), logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample of train sentences:\n",
      "['= Valkyria Chronicles III = \\n \\n Senjō no Valkyria 3 : <unk> Chronicles ( Japanese : 戦場のヴァルキュリア3 , lit .', 'Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable .', 'Released in January 2011 in Japan , it is the third game in the Valkyria series .', '<unk> the same fusion of tactical and real @-@ time gameplay as its predecessors , the story runs parallel to the first game and follows the \" Nameless \" , a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit \" <unk> Raven \" .', 'The game began development in 2010 , carrying over a large portion of the work done on Valkyria Chronicles II .']\n",
      "\n",
      "Sample of test sentences:\n",
      "['= Robert <unk> = \\n \\n Robert <unk> is an English film , television and theatre actor .', 'He had a guest @-@ starring role on the television series The Bill in 2000 .', 'This was followed by a starring role in the play Herons written by Simon Stephens , which was performed in 2001 at the Royal Court Theatre .', 'He had a guest role in the television series Judge John <unk> in 2002 .', 'In 2004 <unk> landed a role as \" Craig \" in the episode \" Teddy \\'s Story \" of the television series The Long Firm ; he starred alongside actors Mark Strong and Derek Jacobi .']\n",
      "\n",
      "Sample of val sentences:\n",
      "['= Homarus gammarus = \\n \\n Homarus gammarus , known as the European lobster or common lobster , is a species of <unk> lobster from the eastern Atlantic Ocean , Mediterranean Sea and parts of the Black Sea .', 'It is closely related to the American lobster , H.', 'americanus .', 'It may grow to a length of 60 cm ( 24 in ) and a mass of 6 kilograms ( 13 lb ) , and bears a conspicuous pair of claws .', 'In life , the lobsters are blue , only becoming \" lobster red \" on cooking .']\n"
     ]
    }
   ],
   "source": [
    "def load_and_preprocess_wikitext(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "\n",
    "    # Use regular expressions to split the text into sentences\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "    sentences = [sentence.strip() for sentence in sentences]\n",
    "    \n",
    "    return sentences\n",
    "\n",
    "train_file_path = \"wikitext-2/wiki.train.tokens\"\n",
    "test_file_path = \"wikitext-2/wiki.test.tokens\"\n",
    "val_file_path = \"wikitext-2/wiki.valid.tokens\"\n",
    "\n",
    "wikitext_sentences_train = load_and_preprocess_wikitext(train_file_path)\n",
    "wikitext_sentences_test = load_and_preprocess_wikitext(test_file_path)\n",
    "wikitext_sentences_val = load_and_preprocess_wikitext(val_file_path)\n",
    "\n",
    "# Print the first few sentences to check\n",
    "print(\"\\nSample of train sentences:\")\n",
    "print(wikitext_sentences_train[:5])\n",
    "print(\"\\nSample of test sentences:\")\n",
    "print(wikitext_sentences_test[:5])\n",
    "print(\"\\nSample of val sentences:\")\n",
    "print(wikitext_sentences_val[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 33281\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "# Hyperparameters\n",
    "BATCH_SIZE = 32\n",
    "PAD_TOKEN = \"<PAD>\"\n",
    "UNK_TOKEN = \"<UNK>\"\n",
    "\n",
    "# Tokenize the data\n",
    "tokens = [word for sentence in wikitext_sentences_train for word in sentence.split()]\n",
    "\n",
    "# Build vocabulary\n",
    "vocab = [PAD_TOKEN, UNK_TOKEN] + list(set(tokens))\n",
    "word_index = {word: index for index, word in enumerate(vocab)}\n",
    "# 添加新的tokens\n",
    "SOS_TOKEN = '<SOS>'\n",
    "EOS_TOKEN = '<EOS>'\n",
    "word_index[SOS_TOKEN] = len(word_index)\n",
    "word_index[EOS_TOKEN] = len(word_index)\n",
    "vocab = {v: k for k, v in word_index.items()}\n",
    "# Convert tokens to integers\n",
    "def tokenize_and_encode(text):\n",
    "    return [word_index.get(word, word_index[UNK_TOKEN]) for word in text.split()]\n",
    "\n",
    "encoded_data_train = [tokenize_and_encode(sentence) for sentence in wikitext_sentences_train]\n",
    "\n",
    "# Create a PyTorch Dataset\n",
    "class WikiDataset(Dataset):\n",
    "    def __init__(self, data, sequence_length):\n",
    "        self.data = data\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        if len(sample) < self.sequence_length:\n",
    "            sample.extend([word_index[PAD_TOKEN]] * (self.sequence_length - len(sample)))\n",
    "        else:\n",
    "            sample = sample[:self.sequence_length]\n",
    "        return torch.tensor(sample)\n",
    "\n",
    "# dataset = WikiDataset(encoded_data_train, SEQUENCE_LENGTH)\n",
    "# dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# Split the data into train and validation sets\n",
    "dataset = WikiDataset(encoded_data_train, SEQ_LEN)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Display a sample batch\n",
    "next(iter(train_dataloader))\n",
    "\n",
    "VOCAB_SIZE = len(vocab)\n",
    "print(f'Vocabulary size: {VOCAB_SIZE}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerCVAE(\n",
       "  (encoder): TransformerEncoder(\n",
       "    (embedding): Embedding(33281, 16)\n",
       "    (transformer_encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=16, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=16, bias=True)\n",
       "          (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fc_logits): Linear(in_features=16, out_features=16, bias=True)\n",
       "  )\n",
       "  (decoder): TransformerDecoder(\n",
       "    (embedding): Embedding(33281, 16)\n",
       "    (transformer_decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=16, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=16, bias=True)\n",
       "          (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fc_out): Linear(in_features=16, out_features=33281, bias=True)\n",
       "    (fc_z): Linear(in_features=16, out_features=16, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing the model with the set hyperparameters\n",
    "transformer_cvae = TransformerCVAE()\n",
    "\n",
    "# Check if GPU is available and move the model to GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "transformer_cvae.to(device)\n",
    "\n",
    "# Define the loss function and the optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(transformer_cvae.parameters(), lr=1e-3)\n",
    "\n",
    "# Display model architecture\n",
    "transformer_cvae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | Loss: 15.9220352 = Recon: 8.6665468 + KLD: 0.7255488:   1%|          | 69/5892 [00:10<14:55,  6.50it/s]  "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 108\u001b[0m\n\u001b[1;32m    105\u001b[0m     plt\u001b[39m.\u001b[39mtitle(\u001b[39m'\u001b[39m\u001b[39mValidation Loss Curve\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    107\u001b[0m num_epochs \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m\n\u001b[0;32m--> 108\u001b[0m train_and_visualize(transformer_cvae, train_dataloader, val_dataloader, optimizer, num_epochs, word_index, vocab)\n",
      "Cell \u001b[0;32mIn[10], line 54\u001b[0m, in \u001b[0;36mtrain_and_visualize\u001b[0;34m(model, train_dataloader, val_dataloader, optimizer, num_epochs, word_index, vocab, beta)\u001b[0m\n\u001b[1;32m     52\u001b[0m batch \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     53\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 54\u001b[0m output, logits \u001b[39m=\u001b[39m model(batch)\n\u001b[1;32m     56\u001b[0m \u001b[39m# 使用新的损失函数\u001b[39;00m\n\u001b[1;32m     57\u001b[0m loss, recon_loss, kld_loss \u001b[39m=\u001b[39m combined_loss_fn(output, batch, logits, beta)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/myCVAE/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[4], line 48\u001b[0m, in \u001b[0;36mTransformerCVAE.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     46\u001b[0m logits, emb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(x)\n\u001b[1;32m     47\u001b[0m z \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreparameterize(logits)\n\u001b[0;32m---> 48\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(emb, z), logits\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/myCVAE/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[4], line 33\u001b[0m, in \u001b[0;36mTransformerDecoder.forward\u001b[0;34m(self, embedded, z)\u001b[0m\n\u001b[1;32m     31\u001b[0m z_adjusted \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc_z(z)\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[1;32m     32\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformer_decoder(embedded, z_adjusted)\n\u001b[0;32m---> 33\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc_out(output\u001b[39m.\u001b[39;49mpermute(\u001b[39m1\u001b[39;49m, \u001b[39m0\u001b[39;49m, \u001b[39m2\u001b[39;49m))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/myCVAE/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/myCVAE/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def generate_text(model, sentence, vocab):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        # Tokenize and encode the sentence\n",
    "        encoded_sentence = tokenize_and_encode(sentence)\n",
    "        input_tensor = torch.tensor([encoded_sentence], dtype=torch.long).to(device)  # Ensure type is Long\n",
    "        \n",
    "        # Pass the encoded sentence through the model encoder\n",
    "        with torch.no_grad():\n",
    "            logits, emb = model.encoder(input_tensor)\n",
    "            z = model.reparameterize(logits)\n",
    "            output = model.decoder(emb, z)\n",
    "        \n",
    "        # Convert the output probabilities to predicted token IDs\n",
    "        _, predicted_ids = torch.max(output, dim=2)\n",
    "        predicted_ids = predicted_ids.squeeze().cpu().numpy()\n",
    "        \n",
    "        # Convert the predicted token IDs back to words\n",
    "        predicted_sentence = ' '.join([vocab[idx] for idx in predicted_ids])\n",
    "        \n",
    "        return predicted_sentence\n",
    "\n",
    "def combined_loss_fn(recon_output, target, logits, beta=1.0):\n",
    "    # 计算重构损失\n",
    "    # recon_output = torch.clamp(recon_output, 1e-10, 1 - 1e-10)\n",
    "    recon_loss = F.cross_entropy(recon_output.view(-1, VOCAB_SIZE), target.view(-1), reduction='mean')\n",
    "\n",
    "    # 计算KLD损失\n",
    "    mean, logvar = torch.chunk(logits, 2, dim=-1)\n",
    "    kld_loss = -0.5 * torch.sum(1 + logvar - mean.pow(2) - logvar.exp())\n",
    "\n",
    "    # 计算总损失\n",
    "    total_loss = recon_loss + beta * kld_loss\n",
    "\n",
    "    return total_loss, recon_loss, kld_loss\n",
    "\n",
    "\n",
    "valid_sentence = \"There were several variants of the <unk> design .\"\n",
    "\n",
    "def train_and_visualize(model, train_dataloader, val_dataloader, optimizer, num_epochs, word_index, vocab, beta=10.0):\n",
    "    losses = []\n",
    "    val_losses = []\n",
    "    recon_losses = []\n",
    "    kld_losses = []\n",
    "    total_steps = len(train_dataloader) * num_epochs\n",
    "\n",
    "    # Initialize tqdm progress bar\n",
    "    progress_bar = tqdm(total=total_steps, desc=\"Training\", position=0)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch in train_dataloader:\n",
    "            batch = batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output, logits = model(batch)\n",
    "            \n",
    "            # 使用新的损失函数\n",
    "            loss, recon_loss, kld_loss = combined_loss_fn(output, batch, logits, beta)\n",
    "            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "            recon_losses.append(recon_loss.item())\n",
    "            kld_losses.append(kld_loss.item())\n",
    "            progress_bar.set_description(f'Epoch {epoch+1}/{num_epochs} | Loss: {loss.item():.7f} = Recon: {recon_loss.item():.7f} + KLD: {kld_loss.item():.7f}')\n",
    "            progress_bar.update(1)\n",
    "\n",
    "        # Print epoch loss\n",
    "        avg_loss = sum(losses[-len(train_dataloader):]) / len(train_dataloader)\n",
    "        print(f\"Done Epoch [{epoch+1}/{num_epochs}] - Loss: {avg_loss:.7f}\")\n",
    "\n",
    "        # Validation after each epoch\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            avg_val_loss = 0\n",
    "            for batch in val_dataloader:\n",
    "                batch = batch.to(device)\n",
    "                output, logits = model(batch)\n",
    "                val_loss, _, _ = combined_loss_fn(output, batch, logits, beta)\n",
    "                val_losses.append(val_loss.item())\n",
    "                avg_val_loss += val_loss.item()\n",
    "            avg_val_loss /= len(val_dataloader)\n",
    "            print(f\"Done Epoch [{epoch+1}/{num_epochs}] - Validation Loss: {avg_val_loss:.7f}\")\n",
    "\n",
    "        # Generate text after each epoch\n",
    "        generated_sentence = generate_text(model, valid_sentence, vocab)\n",
    "        print(f\"Input: {valid_sentence} ---> Echo: {generated_sentence}\\n\")\n",
    "\n",
    "    # Close the tqdm progress bar\n",
    "    progress_bar.close()\n",
    "\n",
    "    # Plot the loss curve\n",
    "    plt.plot(losses, label='Total Loss')\n",
    "    plt.plot(recon_losses, label='Reconstruction Loss')\n",
    "    plt.plot(kld_losses, label='KLD Loss')\n",
    "    plt.xlabel('Steps')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss Curve')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot the validation loss curve\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Batches')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Validation Loss Curve')\n",
    "\n",
    "num_epochs = 3\n",
    "train_and_visualize(transformer_cvae, train_dataloader, val_dataloader, optimizer, num_epochs, word_index, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_sentence = \"Development work took approximately three years .\"\n",
    "test_generate = generate_text(transformer_cvae, valid_sentence, vocab)\n",
    "test_generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the latent space\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_latent_space(model, dataloader, device):\n",
    "    model.eval()\n",
    "    \n",
    "    # Collect logits from the encoder\n",
    "    logits_list = []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            batch = batch.to(device)\n",
    "            logits, _ = model.encoder(batch)\n",
    "            logits_list.append(logits)\n",
    "    \n",
    "    logits_array = torch.cat(logits_list).cpu().numpy()\n",
    "\n",
    "    # Perform t-SNE\n",
    "    tsne = TSNE(n_components=2, random_state=1024)\n",
    "    logits_2d = tsne.fit_transform(logits_array)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.scatter(logits_2d[:, 0], logits_2d[:, 1], alpha=0.5)\n",
    "    plt.title(\"t-SNE visualization of logits\")\n",
    "    plt.show()\n",
    "\n",
    "# After training, call the visualization function\n",
    "visualize_latent_space(transformer_cvae, train_dataloader, device)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: Signal Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Agent:\n",
    "#     def __init__(self, model, id):\n",
    "#         self.model = model\n",
    "#         self.id = id\n",
    "#         self.influence = 1.0\n",
    "#         self.lifespan = 3\n",
    "#         self.age = 0\n",
    "#         self.alive = True\n",
    "    \n",
    "#     def send(self, sentence):\n",
    "#         \"\"\" Encode a sentence into a latent state \"\"\"\n",
    "#         # Tokenize and encode the sentence\n",
    "#         encoded_sentence = tokenize_and_encode(sentence)\n",
    "#         input_tensor = torch.tensor([encoded_sentence], dtype=torch.long).to(device)\n",
    "        \n",
    "#         # Pass the encoded sentence through the model encoder to get logits\n",
    "#         logits = self.model.encoder(input_tensor)\n",
    "        \n",
    "#         # Reparameterize the logits to get the latent state\n",
    "#         z = self.model.reparameterize(logits)\n",
    "#         return z.squeeze().detach()\n",
    "    \n",
    "#     def receive(self, z):\n",
    "#         \"\"\" Decode a latent state into a sentence \"\"\"\n",
    "#         # Convert z to the required shape and type\n",
    "#         z = torch.tensor(z, dtype=torch.float).unsqueeze(0).to(device)\n",
    "        \n",
    "#         # Prepare a <START> token as input for the decoder\n",
    "#         start_token = word_to_index[\"<START>\"]\n",
    "#         input_tensor = torch.tensor([[start_token]], dtype=torch.long).to(device)\n",
    "        \n",
    "#         # Decode the latent state\n",
    "#         output = self.model.decoder(input_tensor, z)\n",
    "        \n",
    "#         # Convert the output probabilities to the predicted token ID\n",
    "#         _, predicted_ids = torch.max(output, dim=2)\n",
    "#         predicted_ids = predicted_ids.squeeze().cpu().numpy()\n",
    "        \n",
    "#         # Convert the predicted token IDs back to a sentence\n",
    "#         predicted_sentence = ' '.join([vocab[idx] for idx in predicted_ids if idx in vocab])\n",
    "#         return predicted_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# # 基于TransformerCVAE的Agent定义\n",
    "# class Agent:\n",
    "#     def __init__(self, model, id, parent_id=None):\n",
    "#         self.model = copy.deepcopy(model)  # 深度复制模型，确保每个agent都有自己的模型权重\n",
    "#         self.id = id\n",
    "#         self.parent_id = parent_id  # 记录父代的ID\n",
    "#         self.influence = 1.0\n",
    "#         self.lifespan = 3\n",
    "#         self.age = 0\n",
    "#         self.alive = True\n",
    "\n",
    "#     def send(self):\n",
    "#         idx = torch.randint(0, len(sentences), (1,)).item()\n",
    "#         sentence = sentences[idx]\n",
    "#         return generate_text(self.model, sentence, vocab)\n",
    "\n",
    "\n",
    "#     def receive(self, sentence):\n",
    "#         self.model.train()\n",
    "#         encoded_sentence = tokenize_and_encode(sentence)\n",
    "#         input_tensor = torch.tensor([encoded_sentence], dtype=torch.long).to(device)\n",
    "#         output, logits = self.model(input_tensor)\n",
    "        \n",
    "#         # 使用新的损失函数\n",
    "#         loss, recon_loss, kld_loss = combined_loss_fn(output, input_tensor, logits, beta=1.0)\n",
    "        \n",
    "#         # 更新影响力\n",
    "#         self.influence *= 1.0 / (1.0 + loss.item())\n",
    "        \n",
    "#         # 返回损失以便于调试\n",
    "#         return loss.item()\n",
    "\n",
    "#     def age_one_year(self):\n",
    "#         self.age += 1\n",
    "#         if self.age > self.lifespan:\n",
    "#             self.alive = False\n",
    "\n",
    "\n",
    "# def simulation(num_generations, initial_population):\n",
    "#     agents = [Agent(transformer_cvae, i) for i in range(initial_population)]\n",
    "#     history = []\n",
    "\n",
    "#     for generation in range(num_generations):\n",
    "#         print(f\"Generation {generation + 1}/{num_generations}\")\n",
    "\n",
    "#         # 让agents互相交流\n",
    "#         for agent in agents:\n",
    "#             if not agent.alive:\n",
    "#                 continue\n",
    "\n",
    "#             # 基于影响力随机选择一个与之交流的agent\n",
    "#             others = [a for a in agents if a.id != agent.id and a.alive]\n",
    "#             influences = torch.tensor([a.influence for a in others])\n",
    "#             influences /= influences.sum()\n",
    "#             idx = torch.multinomial(influences, 1).item()\n",
    "#             partner = others[idx]\n",
    "            \n",
    "#             message = agent.send()\n",
    "#             partner.receive(message)\n",
    "            \n",
    "#         # 基于影响力确定哪些agent会繁殖\n",
    "#         total_influence = sum([agent.influence for agent in agents if agent.alive])\n",
    "#         offspring = []\n",
    "#         for agent in agents:\n",
    "#             if not agent.alive:\n",
    "#                 continue\n",
    "\n",
    "#             num_children = int((agent.influence / total_influence) * initial_population)\n",
    "#             for _ in range(num_children):\n",
    "#                 new_id = max([a.id for a in agents]) + 1\n",
    "#                 offspring.append(Agent(agent.model, new_id, parent_id=agent.id))\n",
    "\n",
    "#         # 更新agent的年龄，并删除已死亡的agent\n",
    "#         for agent in agents:\n",
    "#             agent.age_one_year()\n",
    "#         agents = [agent for agent in agents if agent.alive]\n",
    "\n",
    "#         # 将新的后代加入到agents中\n",
    "#         agents.extend(offspring)\n",
    "\n",
    "#         # 记录这一代的信息\n",
    "#         history.append({\n",
    "#             \"generation\": generation,\n",
    "#             \"num_agents\": len(agents),\n",
    "#             \"average_influence\": sum([agent.influence for agent in agents]) / len(agents),\n",
    "#             \"max_influence\": max([agent.influence for agent in agents]),\n",
    "#             \"min_influence\": min([agent.influence for agent in agents])\n",
    "#         })\n",
    "\n",
    "#     return history\n",
    "\n",
    "# # 提取句子列表\n",
    "# sentences = []\n",
    "# for batch in train_dataloader:\n",
    "#     for seq in batch:\n",
    "#         sentence = ' '.join([vocab[idx.item()] for idx in seq])\n",
    "#         sentences.append(sentence)\n",
    "\n",
    "\n",
    "# # 调用仿真函数\n",
    "# history = simulation(num_generations=10, initial_population=10)\n",
    "\n",
    "# # 打印历史记录\n",
    "# for record in history:\n",
    "#     print(record)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# import torch\n",
    "# from torch import nn\n",
    "# import torch.nn.functional as F\n",
    "# from tqdm.notebook import tqdm\n",
    "\n",
    "# class Agent:\n",
    "#     def __init__(self, model, id):\n",
    "#         self.model = model\n",
    "#         self.id = id\n",
    "#         self.influence = 1.0\n",
    "#         self.lifespan = 3\n",
    "#         self.age = 0\n",
    "#         self.alive = True\n",
    "\n",
    "#     def send(self):\n",
    "#         idx = torch.randint(0, len(sentences), (1,)).item()\n",
    "#         sentence = sentences[idx]\n",
    "#         return generate_text(self.model, sentence, vocab), sentence\n",
    "\n",
    "#     def receive(self, message, true_sentence):\n",
    "#         received_message = generate_text(self.model, true_sentence, vocab)\n",
    "#         # Here, we can set a simple criterion for successful communication, \n",
    "#         # for example, if the received_message is the same as the original message.\n",
    "#         # This can be adjusted based on the requirements.\n",
    "#         success = (received_message == message)\n",
    "#         if success:\n",
    "#             self.influence += 0.1  # Increase influence if the communication is successful\n",
    "#         else:\n",
    "#             self.influence -= 0.1  # Decrease influence if the communication fails\n",
    "#         self.influence = max(0.1, self.influence)  # Ensure influence is never below 0.1\n",
    "#         return success\n",
    "\n",
    "#     def age_one_year(self):\n",
    "#         self.age += 1\n",
    "#         if self.age >= self.lifespan:\n",
    "#             self.alive = False\n",
    "            \n",
    "\n",
    "# def simulation(num_generations=10, initial_population=10):\n",
    "#     population = [Agent(TransformerCVAE().to(device), id=i) for i in range(initial_population)]\n",
    "#     history = []\n",
    "\n",
    "#     for generation in range(num_generations):\n",
    "#         record = {\n",
    "#             'generation': generation,\n",
    "#             'population_size': len(population),\n",
    "#             'avg_influence': sum([agent.influence for agent in population]) / len(population),\n",
    "#             'successful_communications': 0,\n",
    "#             'total_communications': 0,\n",
    "#             'communications': []\n",
    "#         }\n",
    "\n",
    "#         # Agents communicate\n",
    "#         for agent in population:\n",
    "#             # The number of times each agent communicates is proportional to its influence\n",
    "#             num_communications = max(1, int(agent.influence * 3))\n",
    "#             for _ in range(num_communications):\n",
    "#                 # An agent tries to communicate with another random agent (but not itself)\n",
    "#                 others = [a for a in population if a.id != agent.id]\n",
    "#                 influences = torch.tensor([a.influence for a in others])\n",
    "#                 influences = F.normalize(influences, p=1, dim=0)\n",
    "#                 idx = torch.multinomial(influences, 1).item()\n",
    "#                 partner = others[idx]\n",
    "                \n",
    "#                 print(f\"Agent {agent.id} -> Agent {partner.id}\")\n",
    "#                 message, true_sentence = agent.send()\n",
    "#                 success = partner.receive(message, true_sentence)\n",
    "                \n",
    "#                 record['communications'].append({\n",
    "#                     'sender': agent.id,\n",
    "#                     'receiver': partner.id,\n",
    "#                     'original_sentence': true_sentence,\n",
    "#                     'sent_message': message,\n",
    "#                     'received_message': generate_text(partner.model, true_sentence, vocab),\n",
    "#                     'successful': success\n",
    "#                 })\n",
    "\n",
    "#                 if success:\n",
    "#                     record['successful_communications'] += 1\n",
    "#                 record['total_communications'] += 1\n",
    "\n",
    "#         # Ageing process\n",
    "#         for agent in population:\n",
    "#             agent.age_one_year()\n",
    "\n",
    "#         # Reproduction based on influence\n",
    "#         new_agents = []\n",
    "#         for agent in population:\n",
    "#             if agent.alive:\n",
    "#                 # The number of offspring is proportional to the agent's influence\n",
    "#                 num_offspring = max(1, int(agent.influence * 3))\n",
    "#                 for _ in range(num_offspring):\n",
    "#                     offspring_model = TransformerCVAE().to(device)\n",
    "#                     # The offspring's model parameters are a copy of the parent's model parameters\n",
    "#                     offspring_model.load_state_dict(agent.model.state_dict())\n",
    "#                     new_agent = Agent(offspring_model, id=len(population) + len(new_agents))\n",
    "#                     new_agents.append(new_agent)\n",
    "        \n",
    "#         # Replace the old population with the new agents\n",
    "#         population = new_agents\n",
    "\n",
    "#         history.append(record)\n",
    "#         print(f\"Generation [{generation}/{num_generations} complete.\")\n",
    "\n",
    "#     return history\n",
    "\n",
    "# # Call the simulation function\n",
    "# history = simulation(num_generations=5, initial_population=5)\n",
    "\n",
    "# # Print the history records\n",
    "# for record in history:\n",
    "#     print(f\"Generation: {record['generation']}\")\n",
    "#     print(f\"Population Size: {record['population_size']}\")\n",
    "#     print(f\"Average Influence: {record['avg_influence']:.2f}\")\n",
    "#     print(f\"Successful Communications: {record['successful_communications']}/{record['total_communications']}\")\n",
    "#     for comm in record['communications']:\n",
    "#         print(f\"  Agent {comm['sender']} -> Agent {comm['receiver']}:\")\n",
    "#         print(f\"    Original Sentence: {comm['original_sentence']}\")\n",
    "#         print(f\"    Sent Message: {comm['sent_message']}\")\n",
    "#         print(f\"    Received Message: {comm['received_message']}\")\n",
    "#         print(f\"    Successful: {comm['successful']}\")\n",
    "#     print(\"=\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pass embeded into decoder instead of using the original x\n",
    "# class TransformerEncoder(nn.Module):\n",
    "#     def __init__(self, d_model=EMBEDDING_DIM, nhead=4, num_layers=2):\n",
    "#         super(TransformerEncoder, self).__init__()\n",
    "#         self.embedding = nn.Embedding(VOCAB_SIZE, d_model)\n",
    "#         self.transformer_encoder = nn.TransformerEncoder(\n",
    "#             nn.TransformerEncoderLayer(d_model, nhead), num_layers\n",
    "#         )\n",
    "#         self.fc_logits = nn.Linear(d_model, LATENT_DIM)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         embedded = self.embedding(x).permute(1, 0, 2)  # Transformer expects seq_len, batch, features\n",
    "#         transformed = self.transformer_encoder(embedded)\n",
    "#         # Use the final state to predict logits for latent space\n",
    "#         logits = self.fc_logits(transformed[-1])\n",
    "#         return logits, embedded\n",
    "\n",
    "\n",
    "# class TransformerDecoder(nn.Module):\n",
    "#     def __init__(self, d_model=EMBEDDING_DIM, nhead=4, num_layers=2):\n",
    "#         super(TransformerDecoder, self).__init__()\n",
    "#         self.embedding = nn.Embedding(VOCAB_SIZE, d_model)\n",
    "#         self.transformer_decoder = nn.TransformerDecoder(\n",
    "#             nn.TransformerDecoderLayer(d_model, nhead), num_layers\n",
    "#         )\n",
    "#         self.fc_out = nn.Linear(d_model, VOCAB_SIZE)\n",
    "#         self.fc_z = nn.Linear(LATENT_DIM, d_model)  # Convert z to feature size for transformer\n",
    "\n",
    "#     def forward(self, embedded, z):\n",
    "#         # embedded = self.embedding(x).permute(1, 0, 2) # Transformer expects [seq_len, batch, features], permute函数用于改变张量的维度顺序\n",
    "#         z_adjusted = self.fc_z(z).unsqueeze(0)\n",
    "#         output = self.transformer_decoder(embedded, z_adjusted)\n",
    "#         return self.fc_out(output.permute(1, 0, 2))\n",
    "\n",
    "\n",
    "# class TransformerCVAE(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(TransformerCVAE, self).__init__()\n",
    "#         self.encoder = TransformerEncoder()\n",
    "#         self.decoder = TransformerDecoder()\n",
    "\n",
    "#     def reparameterize(self, logits):\n",
    "#         return F.gumbel_softmax(logits, tau=TAU, hard=False, dim=-1)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         logits, emb = self.encoder(x)\n",
    "#         z = self.reparameterize(logits)\n",
    "#         return self.decoder(emb, z), logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, model, id):\n",
    "        self.model = model\n",
    "        self.id = id\n",
    "        self.influence = 1.0\n",
    "        self.lifespan = 3\n",
    "        self.age = 0\n",
    "        self.alive = True\n",
    "\n",
    "    def send(self, input_tensor):\n",
    "        \n",
    "        # Use the encoder to encode the sentence\n",
    "        logits, embed = self.model.encoder(input_tensor)\n",
    "        msg = self.model.reparameterize(logits)\n",
    "        return msg, embed, logits\n",
    "\n",
    "    def receive(self, msg, embed):\n",
    "        # Use the decoder to decode the message\n",
    "        decoded_output = self.model.decoder(embed, msg)\n",
    "        \n",
    "        # Convert the output probabilities to predicted token IDs\n",
    "        _, predicted_ids = torch.max(decoded_output, dim=2)\n",
    "        predicted_ids = predicted_ids.squeeze().cpu().numpy()\n",
    "        \n",
    "        # Convert the predicted token IDs back to words\n",
    "        decoded_sentence = ' '.join([vocab[idx] for idx in predicted_ids])\n",
    "        return decoded_output, decoded_sentence\n",
    "\n",
    "    def age_one_year(self):\n",
    "        self.age += 1\n",
    "        if self.age >= self.lifespan:\n",
    "            self.alive = False\n",
    "            \n",
    "\n",
    "def simulation(num_generations=10, initial_population=10):\n",
    "    population = [Agent(transformer_cvae.to(device), id=i) for i in range(initial_population)]\n",
    "    history = []\n",
    "\n",
    "    for generation in range(num_generations):\n",
    "        record = {\n",
    "            'generation': generation,\n",
    "            'population_size': len(population),\n",
    "            'avg_influence': sum([agent.influence for agent in population]) / len(population),\n",
    "            'successful_communications': 0,\n",
    "            'total_communications': 0,\n",
    "            'successful_communication_rate': 0,\n",
    "            'avg_loss': 0,\n",
    "            'communications': []\n",
    "        }\n",
    "\n",
    "        # Agents communicate\n",
    "        for agent in population:\n",
    "            optimizer_sender = torch.optim.AdamW(agent.model.parameters())\n",
    "            # The number of times each agent communicates is proportional to its influence\n",
    "            num_communications = max(1, int(agent.influence * 3))\n",
    "            for _ in range(num_communications):\n",
    "                # An agent tries to communicate with another random agent (but not itself)\n",
    "                others = [a for a in population if a.id != agent.id]\n",
    "                influences = torch.tensor([a.influence for a in others])\n",
    "                influences = F.normalize(influences, p=1, dim=0)\n",
    "                idx = torch.multinomial(influences, 1).item()\n",
    "                partner = others[idx]\n",
    "                optimizer_receiver = torch.optim.AdamW(partner.model.parameters())\n",
    "\n",
    "                idx = torch.randint(0, len(sentences), (1,)).item()\n",
    "                sentence = sentences[idx]\n",
    "                # Tokenize and encode the sentence\n",
    "                encoded_sentence = tokenize_and_encode(sentence)\n",
    "                input_tensor = torch.tensor([encoded_sentence], dtype=torch.long).to(device)\n",
    "                \n",
    "                msg, emb, logit = agent.send(input_tensor)\n",
    "                d_tensor, d_sentence = partner.receive(msg, emb)\n",
    "                # print(f\"Sender {agent.id}: {sentence} -> Receiver {partner.id}: {d_sentence}\")\n",
    "                loss,_,_ = combined_loss_fn(d_tensor, input_tensor, logit, beta=1.0)\n",
    "                loss.backward()\n",
    "                optimizer_sender.step()\n",
    "                optimizer_receiver.step()\n",
    "\n",
    "                # if d_sentence == sentence:\n",
    "                if loss.item() < 0.1:\n",
    "                    success = True\n",
    "                    agent.influence += 0.1\n",
    "                    partner.influence += 0.1\n",
    "                else:\n",
    "                    success = False\n",
    "                    agent.influence -= 0.1\n",
    "                    partner.influence -= 0.1\n",
    "                \n",
    "                record['communications'].append({\n",
    "                    'sender': agent.id,\n",
    "                    'receiver': partner.id,\n",
    "                    'original_sentence': sentence,\n",
    "                    'decoded_sentence': d_sentence,\n",
    "                    'successful': success,\n",
    "                    'loss': loss.item()\n",
    "                })\n",
    "\n",
    "                if success:\n",
    "                    record['successful_communications'] += 1\n",
    "                record['total_communications'] += 1\n",
    "                record['avg_loss'] += loss.item()\n",
    "            record['successful_communication_rate'] = record['successful_communications'] / record['total_communications']\n",
    "            record['avg_loss'] /= record['total_communications']\n",
    "        \n",
    "        # Ageing process\n",
    "        for agent in population:\n",
    "            agent.age_one_year()\n",
    "\n",
    "        # Reproduction based on influence\n",
    "        new_agents = []\n",
    "        for agent in population:\n",
    "            if agent.alive:\n",
    "                # The number of offspring is proportional to the agent's influence\n",
    "                num_offspring = max(1, int(agent.influence * 3))\n",
    "                for _ in range(num_offspring):\n",
    "                    offspring_model = TransformerCVAE().to(device)\n",
    "                    # The offspring's model parameters are a copy of the parent's model parameters\n",
    "                    offspring_model.load_state_dict(agent.model.state_dict())\n",
    "                    new_agent = Agent(offspring_model, id=len(population) + len(new_agents))\n",
    "                    new_agents.append(new_agent)\n",
    "        \n",
    "        # Replace the old population with the new agents\n",
    "        population = new_agents\n",
    "\n",
    "        history.append(record)\n",
    "        print(f\"Generation [{generation}/{num_generations}] Done\")\n",
    "\n",
    "    return history\n",
    "\n",
    "# 提取句子列表\n",
    "sentences = []\n",
    "for batch in train_dataloader:\n",
    "    for seq in batch:\n",
    "        sentence = ' '.join([vocab[idx.item()] for idx in seq])\n",
    "        sentences.append(sentence)\n",
    "# Call the simulation function\n",
    "history = simulation(num_generations=25, initial_population=3)\n",
    "\n",
    "# Print the history records\n",
    "for record in history:\n",
    "    print(f\"Generation: {record['generation']}\")\n",
    "    print(f\"Population Size: {record['population_size']}\")\n",
    "    print(f\"Average Influence: {record['avg_influence']:.2f}\")\n",
    "    print(f\"Successful Communications: {record['successful_communications']}/{record['total_communications']}\")\n",
    "    print(f\"Successful Communication Rate: {record['successful_communication_rate']:.7f}\")\n",
    "    print(f\"Average Communication Loss: {record['avg_loss']:.7f}\")\n",
    "    for comm in record['communications']:\n",
    "        print(f\"  Agent {comm['sender']} -> Agent {comm['receiver']}:\")\n",
    "        print(f\"    Original Sentence: {comm['original_sentence']}\")\n",
    "        print(f\"    Decoded Sentence: {comm['decoded_sentence']}\")\n",
    "        print(f\"    Successful: {comm['successful']}\")\n",
    "        print(f\"    Loss: {comm['loss']:.7f}\")\n",
    "    print(\"=\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_sentence = \"This included extensive evidence for the production of high status jewellery and moulds from the seventh\"\n",
    "test_generate = generate_text(transformer_cvae, valid_sentence, vocab)\n",
    "test_generate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "平均适应度变化:\n",
    "\n",
    "记录所有agents的适应度平均值，并在每个周期后绘制它。这将为您提供一个关于整体群体如何进化的视图。\n",
    "\n",
    "python\n",
    "Copy code\n",
    "avg_fitness = sum([agent.fitness for agent in agents]) / len(agents)\n",
    "最佳和最差适应度变化:\n",
    "\n",
    "跟踪并可视化最佳和最差适应度的agents。这有助于了解适应度分布的范围如何随时间变化。\n",
    "\n",
    "模型权重分布:\n",
    "\n",
    "为了了解权重如何传播，您可以使用某种可视化工具（如PCA或t-SNE）来可视化agent模型权重的分布。如果你看到权重聚集在某些区域，这可能意味着某些特定的模型结构正在变得主导。\n",
    "\n",
    "种群大小:\n",
    "\n",
    "如果你允许agents繁殖，那么绘制种群大小作为时间函数可能会很有趣。这有助于你了解种群是如何增长或收缩的，以及是否有任何爆炸性增长或大量死亡。\n",
    "\n",
    "交互效果示例:\n",
    "\n",
    "随机选择一些句子并展示agent如何对它们进行编码和解码。这有助于定性地了解agents的性能。\n",
    "\n",
    "适应度分布直方图:\n",
    "\n",
    "在每个周期或几个周期后，您可以为所有agents的适应度绘制一个直方图，以查看适应度如何分布。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模拟实时展示:\n",
    "a. 动态代表每个Agent:\n",
    "使用小圆圈或其他形状代表每个agent。\n",
    "使用不同的颜色或大小来表示agent的适应度或权重。\n",
    "b. 实时交互:\n",
    "当agent互相交流时，显示连线或动画效果。\n",
    "当新的agent生成或某个agent消失时，显示出现或消失的动画效果。\n",
    "c. 时间控制:\n",
    "允许用户暂停、开始或加速模拟。\n",
    "d. 参数调整:\n",
    "提供滑块或输入框，让用户调整模拟参数，如初始agent数量、交流频率、权重传播速率等。\n",
    "2. 交互式可视化:\n",
    "a. 数据视图切换:\n",
    "允许用户在不同的视图之间切换，例如适应度曲线、权重分布图、种群大小随时间变化的图等。\n",
    "b. 工具提示和详细信息:\n",
    "当用户将鼠标悬停在某个数据点或agent上时，显示详细的信息或统计数据。\n",
    "c. 参数调整:\n",
    "提供控件，允许用户修改可视化的参数。例如，查看在不同权重传播策略下的适应度曲线。\n",
    "d. 交互式教程:\n",
    "为用户提供一个交互式教程，引导他们了解如何使用可视化工具，以及他们可以从中学到什么。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myCVAE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
