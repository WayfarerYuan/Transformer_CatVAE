{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import 必要的库："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import Counter\n",
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据处理："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'the': 4964,\n",
       "         'of': 2571,\n",
       "         'unk': 2369,\n",
       "         'and': 2240,\n",
       "         'in': 1686,\n",
       "         'to': 1645,\n",
       "         'a': 1506,\n",
       "         'was': 869,\n",
       "         'The': 812,\n",
       "         'with': 678,\n",
       "         'for': 644,\n",
       "         'as': 627,\n",
       "         's': 622,\n",
       "         'that': 617,\n",
       "         'is': 552,\n",
       "         'on': 552,\n",
       "         'by': 489,\n",
       "         'were': 392,\n",
       "         'at': 355,\n",
       "         'from': 346,\n",
       "         'his': 340,\n",
       "         'are': 302,\n",
       "         'an': 264,\n",
       "         'her': 255,\n",
       "         'which': 252,\n",
       "         'In': 244,\n",
       "         'he': 221,\n",
       "         'be': 219,\n",
       "         'had': 212,\n",
       "         'it': 204,\n",
       "         'their': 186,\n",
       "         'gods': 175,\n",
       "         'or': 174,\n",
       "         'has': 169,\n",
       "         'also': 167,\n",
       "         'not': 164,\n",
       "         'one': 156,\n",
       "         'who': 153,\n",
       "         'but': 148,\n",
       "         'two': 148,\n",
       "         'its': 137,\n",
       "         'she': 137,\n",
       "         'have': 133,\n",
       "         'this': 130,\n",
       "         'other': 126,\n",
       "         'Fey': 125,\n",
       "         'first': 124,\n",
       "         'Townsend': 121,\n",
       "         'all': 116,\n",
       "         'more': 114,\n",
       "         'time': 109,\n",
       "         'been': 108,\n",
       "         'album': 108,\n",
       "         'He': 106,\n",
       "         '1': 106,\n",
       "         'deities': 101,\n",
       "         'they': 100,\n",
       "         'after': 100,\n",
       "         'She': 96,\n",
       "         'gold': 94,\n",
       "         'into': 93,\n",
       "         'aircraft': 91,\n",
       "         'only': 90,\n",
       "         'game': 87,\n",
       "         'GA': 87,\n",
       "         'Shiva': 87,\n",
       "         'It': 86,\n",
       "         'most': 85,\n",
       "         'god': 83,\n",
       "         'Trujillo': 83,\n",
       "         'year': 82,\n",
       "         'would': 82,\n",
       "         'up': 80,\n",
       "         'these': 79,\n",
       "         'I': 79,\n",
       "         'over': 78,\n",
       "         'than': 78,\n",
       "         'during': 77,\n",
       "         'A': 77,\n",
       "         'being': 77,\n",
       "         '2': 77,\n",
       "         'many': 76,\n",
       "         'four': 76,\n",
       "         'three': 75,\n",
       "         'made': 75,\n",
       "         'some': 74,\n",
       "         'dollar': 73,\n",
       "         'could': 72,\n",
       "         'Egyptian': 71,\n",
       "         'about': 69,\n",
       "         'both': 68,\n",
       "         'when': 68,\n",
       "         'them': 68,\n",
       "         'This': 68,\n",
       "         'such': 67,\n",
       "         'team': 67,\n",
       "         'between': 67,\n",
       "         'season': 67,\n",
       "         'out': 66,\n",
       "         'Rock': 66,\n",
       "         'new': 65,\n",
       "         'him': 64,\n",
       "         'under': 63,\n",
       "         'well': 62,\n",
       "         'while': 61,\n",
       "         'work': 59,\n",
       "         'through': 59,\n",
       "         'later': 59,\n",
       "         '4': 58,\n",
       "         'used': 58,\n",
       "         'May': 57,\n",
       "         'began': 56,\n",
       "         'part': 56,\n",
       "         'each': 56,\n",
       "         'New': 56,\n",
       "         'series': 55,\n",
       "         'Valkyria': 54,\n",
       "         'where': 54,\n",
       "         'can': 54,\n",
       "         'Eaton': 54,\n",
       "         'no': 53,\n",
       "         'Little': 53,\n",
       "         '3': 51,\n",
       "         'called': 51,\n",
       "         'years': 51,\n",
       "         'there': 51,\n",
       "         'divine': 51,\n",
       "         'so': 50,\n",
       "         'end': 50,\n",
       "         'same': 49,\n",
       "         'After': 49,\n",
       "         'became': 49,\n",
       "         '000': 49,\n",
       "         '5': 49,\n",
       "         'released': 48,\n",
       "         'like': 48,\n",
       "         'known': 48,\n",
       "         'world': 48,\n",
       "         'before': 48,\n",
       "         'seen': 48,\n",
       "         'against': 47,\n",
       "         'On': 47,\n",
       "         'left': 47,\n",
       "         'small': 47,\n",
       "         'record': 47,\n",
       "         'any': 46,\n",
       "         'back': 46,\n",
       "         'Cullen': 46,\n",
       "         'several': 45,\n",
       "         'Barker': 45,\n",
       "         'power': 45,\n",
       "         'war': 44,\n",
       "         'then': 44,\n",
       "         'number': 44,\n",
       "         'second': 44,\n",
       "         'Blue': 44,\n",
       "         'Madero': 44,\n",
       "         'received': 43,\n",
       "         'main': 43,\n",
       "         'UK': 43,\n",
       "         'including': 43,\n",
       "         'Jackets': 43,\n",
       "         'following': 42,\n",
       "         'South': 42,\n",
       "         'United': 42,\n",
       "         '6': 42,\n",
       "         'Fernandez': 42,\n",
       "         'caves': 42,\n",
       "         '2011': 41,\n",
       "         'played': 41,\n",
       "         'did': 41,\n",
       "         'long': 41,\n",
       "         '7': 41,\n",
       "         'operations': 40,\n",
       "         'November': 40,\n",
       "         'They': 40,\n",
       "         'form': 40,\n",
       "         'm': 40,\n",
       "         'Chronicles': 39,\n",
       "         'games': 39,\n",
       "         'There': 39,\n",
       "         'early': 39,\n",
       "         'state': 39,\n",
       "         'Columbus': 39,\n",
       "         'ship': 39,\n",
       "         'As': 38,\n",
       "         'took': 38,\n",
       "         'another': 38,\n",
       "         'No': 38,\n",
       "         'history': 38,\n",
       "         'flying': 38,\n",
       "         'coins': 38,\n",
       "         'role': 37,\n",
       "         'although': 37,\n",
       "         'own': 37,\n",
       "         'said': 37,\n",
       "         'name': 37,\n",
       "         'life': 37,\n",
       "         'women': 37,\n",
       "         'NHL': 37,\n",
       "         'place': 36,\n",
       "         'novel': 36,\n",
       "         'head': 36,\n",
       "         'ft': 36,\n",
       "         'These': 36,\n",
       "         'air': 36,\n",
       "         'British': 36,\n",
       "         'Urania': 36,\n",
       "         'cave': 36,\n",
       "         'character': 35,\n",
       "         'found': 35,\n",
       "         'around': 35,\n",
       "         'events': 35,\n",
       "         'day': 35,\n",
       "         'often': 35,\n",
       "         'important': 35,\n",
       "         'regime': 35,\n",
       "         'along': 34,\n",
       "         'down': 34,\n",
       "         'based': 34,\n",
       "         'within': 34,\n",
       "         'human': 34,\n",
       "         'group': 34,\n",
       "         'per': 33,\n",
       "         'last': 33,\n",
       "         'music': 33,\n",
       "         'April': 33,\n",
       "         'built': 33,\n",
       "         'States': 33,\n",
       "         '12': 33,\n",
       "         'high': 33,\n",
       "         'Kingdom': 33,\n",
       "         'film': 33,\n",
       "         'third': 32,\n",
       "         'military': 32,\n",
       "         'five': 32,\n",
       "         'order': 32,\n",
       "         'John': 32,\n",
       "         'band': 32,\n",
       "         'family': 32,\n",
       "         'Blackie': 32,\n",
       "         'described': 32,\n",
       "         'struck': 32,\n",
       "         'Slayer': 32,\n",
       "         'coin': 32,\n",
       "         'produced': 31,\n",
       "         'much': 31,\n",
       "         'February': 31,\n",
       "         'World': 31,\n",
       "         '30': 31,\n",
       "         'use': 31,\n",
       "         'father': 31,\n",
       "         '2008': 31,\n",
       "         'career': 31,\n",
       "         'deity': 31,\n",
       "         'right': 31,\n",
       "         'Vargas': 31,\n",
       "         'Llosa': 31,\n",
       "         'SNL': 31,\n",
       "         'Parvati': 31,\n",
       "         'War': 30,\n",
       "         'large': 30,\n",
       "         'off': 30,\n",
       "         'single': 30,\n",
       "         'class': 30,\n",
       "         'himself': 30,\n",
       "         '10': 30,\n",
       "         'hand': 30,\n",
       "         'may': 30,\n",
       "         'City': 30,\n",
       "         't': 30,\n",
       "         'N': 30,\n",
       "         'York': 30,\n",
       "         'comedy': 30,\n",
       "         'reaction': 30,\n",
       "         'At': 29,\n",
       "         'just': 29,\n",
       "         'live': 29,\n",
       "         '2012': 29,\n",
       "         'show': 29,\n",
       "         'Egyptians': 29,\n",
       "         'figure': 29,\n",
       "         'Díaz': 29,\n",
       "         'While': 28,\n",
       "         'points': 28,\n",
       "         'make': 28,\n",
       "         'until': 28,\n",
       "         'due': 28,\n",
       "         'June': 28,\n",
       "         'Arkansas': 28,\n",
       "         'though': 28,\n",
       "         'Dominican': 28,\n",
       "         'Strapping': 28,\n",
       "         'Young': 28,\n",
       "         'development': 27,\n",
       "         '2010': 27,\n",
       "         'original': 27,\n",
       "         'book': 27,\n",
       "         'different': 27,\n",
       "         'female': 27,\n",
       "         'stated': 27,\n",
       "         'considered': 27,\n",
       "         'continued': 27,\n",
       "         'way': 27,\n",
       "         'south': 27,\n",
       "         'St': 27,\n",
       "         'given': 27,\n",
       "         'commercial': 27,\n",
       "         'Mint': 27,\n",
       "         'Devin': 27,\n",
       "         'those': 26,\n",
       "         'present': 26,\n",
       "         'next': 26,\n",
       "         'design': 26,\n",
       "         'His': 26,\n",
       "         'set': 26,\n",
       "         'half': 26,\n",
       "         '0': 26,\n",
       "         'east': 26,\n",
       "         '13': 26,\n",
       "         'late': 26,\n",
       "         '2006': 26,\n",
       "         'national': 26,\n",
       "         '2009': 26,\n",
       "         'believed': 26,\n",
       "         'Atlanta': 26,\n",
       "         'ships': 26,\n",
       "         'pilots': 26,\n",
       "         'albums': 26,\n",
       "         'RAAF': 26,\n",
       "         'WASP': 26,\n",
       "         'Lad': 26,\n",
       "         'characters': 25,\n",
       "         'throughout': 25,\n",
       "         'public': 25,\n",
       "         'include': 25,\n",
       "         'self': 25,\n",
       "         'Tower': 25,\n",
       "         'building': 25,\n",
       "         'tower': 25,\n",
       "         'named': 25,\n",
       "         'government': 25,\n",
       "         'American': 25,\n",
       "         'held': 25,\n",
       "         '8': 25,\n",
       "         'country': 25,\n",
       "         'Navy': 25,\n",
       "         'wrote': 25,\n",
       "         '2007': 25,\n",
       "         'Egypt': 25,\n",
       "         'dollars': 25,\n",
       "         'take': 24,\n",
       "         'support': 24,\n",
       "         'addition': 24,\n",
       "         'play': 24,\n",
       "         'light': 24,\n",
       "         'leading': 24,\n",
       "         '15': 24,\n",
       "         'people': 24,\n",
       "         'sent': 24,\n",
       "         'near': 24,\n",
       "         'remained': 24,\n",
       "         'even': 24,\n",
       "         '19': 24,\n",
       "         'Her': 24,\n",
       "         'death': 24,\n",
       "         'Australia': 24,\n",
       "         'appeared': 24,\n",
       "         'former': 24,\n",
       "         'Some': 24,\n",
       "         'aerodromes': 24,\n",
       "         'pilot': 24,\n",
       "         'Zrínyi': 24,\n",
       "         'outside': 23,\n",
       "         'January': 23,\n",
       "         'previous': 23,\n",
       "         'forces': 23,\n",
       "         'player': 23,\n",
       "         'city': 23,\n",
       "         'General': 23,\n",
       "         'position': 23,\n",
       "         'best': 23,\n",
       "         'still': 23,\n",
       "         'Flower': 23,\n",
       "         'Arsenal': 23,\n",
       "         'James': 23,\n",
       "         'local': 23,\n",
       "         '18': 23,\n",
       "         'month': 23,\n",
       "         'above': 23,\n",
       "         'Union': 23,\n",
       "         'area': 23,\n",
       "         'mother': 23,\n",
       "         'religious': 23,\n",
       "         'trade': 23,\n",
       "         'represented': 23,\n",
       "         'India': 23,\n",
       "         'Austro': 23,\n",
       "         'Hungarian': 23,\n",
       "         'flight': 23,\n",
       "         'temples': 23,\n",
       "         'Heaven': 23,\n",
       "         'aviation': 23,\n",
       "         'story': 22,\n",
       "         'returned': 22,\n",
       "         'members': 22,\n",
       "         'written': 22,\n",
       "         'When': 22,\n",
       "         'recorded': 22,\n",
       "         'since': 22,\n",
       "         'central': 22,\n",
       "         'arms': 22,\n",
       "         'came': 22,\n",
       "         'March': 22,\n",
       "         'point': 22,\n",
       "         'behind': 22,\n",
       "         'Most': 22,\n",
       "         '11': 22,\n",
       "         'now': 22,\n",
       "         'species': 22,\n",
       "         'Philadelphia': 22,\n",
       "         'star': 22,\n",
       "         'put': 22,\n",
       "         'silver': 22,\n",
       "         'rock': 22,\n",
       "         'Squadron': 22,\n",
       "         'shrine': 22,\n",
       "         'transport': 22,\n",
       "         'CAA': 22,\n",
       "         'Longacre': 22,\n",
       "         'island': 22,\n",
       "         'release': 21,\n",
       "         'control': 21,\n",
       "         'limited': 21,\n",
       "         'if': 21,\n",
       "         'With': 21,\n",
       "         'times': 21,\n",
       "         'major': 21,\n",
       "         'production': 21,\n",
       "         'song': 21,\n",
       "         'forms': 21,\n",
       "         'others': 21,\n",
       "         'damaged': 21,\n",
       "         'established': 21,\n",
       "         'men': 21,\n",
       "         'troops': 21,\n",
       "         'All': 21,\n",
       "         'activities': 21,\n",
       "         'less': 21,\n",
       "         'October': 21,\n",
       "         'north': 21,\n",
       "         'side': 21,\n",
       "         'Fairies': 21,\n",
       "         'broken': 21,\n",
       "         '9': 21,\n",
       "         'million': 21,\n",
       "         'contract': 21,\n",
       "         '2013': 21,\n",
       "         'led': 21,\n",
       "         'shown': 21,\n",
       "         'Erzherzog': 21,\n",
       "         'Amun': 21,\n",
       "         'figures': 21,\n",
       "         'metal': 21,\n",
       "         'Air': 21,\n",
       "         'Goat': 21,\n",
       "         'Republic': 21,\n",
       "         'developed': 20,\n",
       "         'real': 20,\n",
       "         'II': 20,\n",
       "         'system': 20,\n",
       "         'carried': 20,\n",
       "         'without': 20,\n",
       "         'do': 20,\n",
       "         'however': 20,\n",
       "         'again': 20,\n",
       "         'project': 20,\n",
       "         'general': 20,\n",
       "         'arsenal': 20,\n",
       "         'But': 20,\n",
       "         'signed': 20,\n",
       "         'lead': 20,\n",
       "         'km': 20,\n",
       "         'North': 20,\n",
       "         'National': 20,\n",
       "         'few': 20,\n",
       "         '17': 20,\n",
       "         'across': 20,\n",
       "         'nature': 20,\n",
       "         'training': 20,\n",
       "         'However': 20,\n",
       "         'writing': 20,\n",
       "         'mm': 20,\n",
       "         'religion': 20,\n",
       "         'goddess': 20,\n",
       "         'assassination': 20,\n",
       "         'Zapata': 20,\n",
       "         'face': 19,\n",
       "         'action': 19,\n",
       "         'popular': 19,\n",
       "         'particular': 19,\n",
       "         'September': 19,\n",
       "         'too': 19,\n",
       "         'songs': 19,\n",
       "         'For': 19,\n",
       "         'federal': 19,\n",
       "         'because': 19,\n",
       "         'common': 19,\n",
       "         'various': 19,\n",
       "         'Gambia': 19,\n",
       "         'final': 19,\n",
       "         '21': 19,\n",
       "         'terms': 19,\n",
       "         'inch': 19,\n",
       "         'political': 19,\n",
       "         'performance': 19,\n",
       "         'Ra': 19,\n",
       "         'image': 19,\n",
       "         'cent': 19,\n",
       "         'reagents': 19,\n",
       "         'theme': 18,\n",
       "         'elements': 18,\n",
       "         'During': 18,\n",
       "         'using': 18,\n",
       "         'become': 18,\n",
       "         'required': 18,\n",
       "         'originally': 18,\n",
       "         'designed': 18,\n",
       "         'felt': 18,\n",
       "         'issue': 18,\n",
       "         'By': 18,\n",
       "         'style': 18,\n",
       "         'August': 18,\n",
       "         'Building': 18,\n",
       "         'US': 18,\n",
       "         '14': 18,\n",
       "         'away': 18,\n",
       "         'guns': 18,\n",
       "         '20': 18,\n",
       "         '16': 18,\n",
       "         'things': 18,\n",
       "         'below': 18,\n",
       "         'size': 18,\n",
       "         'Although': 18,\n",
       "         'start': 18,\n",
       "         'deal': 18,\n",
       "         'December': 18,\n",
       "         'track': 18,\n",
       "         'reviews': 18,\n",
       "         'humans': 18,\n",
       "         'creation': 18,\n",
       "         'creator': 18,\n",
       "         'temple': 18,\n",
       "         'carbonaria': 18,\n",
       "         'ylide': 18,\n",
       "         'III': 17,\n",
       "         'Second': 17,\n",
       "         'top': 17,\n",
       "         'either': 17,\n",
       "         'names': 17,\n",
       "         'home': 17,\n",
       "         'great': 17,\n",
       "         'force': 17,\n",
       "         'what': 17,\n",
       "         'created': 17,\n",
       "         'involved': 17,\n",
       "         'An': 17,\n",
       "         'particularly': 17,\n",
       "         'site': 17,\n",
       "         'writer': 17,\n",
       "         'aspects': 17,\n",
       "         'located': 17,\n",
       "         'issued': 17,\n",
       "         'among': 17,\n",
       "         'further': 17,\n",
       "         'days': 17,\n",
       "         'performed': 17,\n",
       "         'gun': 17,\n",
       "         'moved': 17,\n",
       "         'larger': 17,\n",
       "         'century': 17,\n",
       "         'published': 17,\n",
       "         'sister': 17,\n",
       "         'child': 17,\n",
       "         'little': 17,\n",
       "         '25': 17,\n",
       "         'never': 17,\n",
       "         'cover': 17,\n",
       "         'feet': 17,\n",
       "         'greater': 17,\n",
       "         'base': 17,\n",
       "         'total': 17,\n",
       "         '44': 17,\n",
       "         '100': 17,\n",
       "         'Italian': 17,\n",
       "         '2015': 17,\n",
       "         'industry': 17,\n",
       "         'co': 17,\n",
       "         'Ferdinand': 17,\n",
       "         'formed': 17,\n",
       "         'Horus': 17,\n",
       "         'past': 17,\n",
       "         'Aviation': 17,\n",
       "         'Darwin': 17,\n",
       "         'playing': 16,\n",
       "         'low': 16,\n",
       "         'franchise': 16,\n",
       "         'To': 16,\n",
       "         'mostly': 16,\n",
       "         'themselves': 16,\n",
       "         'command': 16,\n",
       "         'material': 16,\n",
       "         'G': 16,\n",
       "         'guitar': 16,\n",
       "         'piece': 16,\n",
       "         'appearance': 16,\n",
       "         '23': 16,\n",
       "         'generally': 16,\n",
       "         'art': 16,\n",
       "         'period': 16,\n",
       "         'personal': 16,\n",
       "         'started': 16,\n",
       "         'River': 16,\n",
       "         'included': 16,\n",
       "         'goal': 16,\n",
       "         'wife': 16,\n",
       "         'private': 16,\n",
       "         'level': 16,\n",
       "         'children': 16,\n",
       "         'hours': 16,\n",
       "         'Association': 16,\n",
       "         'range': 16,\n",
       "         'free': 16,\n",
       "         'joined': 16,\n",
       "         'night': 16,\n",
       "         'Charles': 16,\n",
       "         'roles': 16,\n",
       "         'SMS': 16,\n",
       "         'Max': 16,\n",
       "         'maat': 16,\n",
       "         'texts': 16,\n",
       "         'fungus': 16,\n",
       "         'cup': 16,\n",
       "         'Mexico': 16,\n",
       "         'president': 16,\n",
       "         'Orozco': 16,\n",
       "         'solo': 16,\n",
       "         'Elephanta': 16,\n",
       "         'specific': 15,\n",
       "         'battle': 15,\n",
       "         'Each': 15,\n",
       "         'remain': 15,\n",
       "         'successful': 15,\n",
       "         'One': 15,\n",
       "         'fire': 15,\n",
       "         'worked': 15,\n",
       "         'People': 15,\n",
       "         'west': 15,\n",
       "         'featured': 15,\n",
       "         'how': 15,\n",
       "         'six': 15,\n",
       "         '1861': 15,\n",
       "         'me': 15,\n",
       "         'hands': 15,\n",
       "         'shows': 15,\n",
       "         'front': 15,\n",
       "         'won': 15,\n",
       "         'Society': 15,\n",
       "         'sometimes': 15,\n",
       "         'influence': 15,\n",
       "         'man': 15,\n",
       "         'round': 15,\n",
       "         'win': 15,\n",
       "         'plain': 15,\n",
       "         'male': 15,\n",
       "         'complex': 15,\n",
       "         'loss': 15,\n",
       "         'draft': 15,\n",
       "         'line': 15,\n",
       "         'Roman': 15,\n",
       "         'sun': 15,\n",
       "         'London': 15,\n",
       "         '88': 15,\n",
       "         'port': 15,\n",
       "         'plan': 15,\n",
       "         'wing': 15,\n",
       "         'rituals': 15,\n",
       "         'Isis': 15,\n",
       "         'cult': 15,\n",
       "         'images': 15,\n",
       "         'sky': 15,\n",
       "         'King': 15,\n",
       "         'noise': 15,\n",
       "         'airspace': 15,\n",
       "         'treaty': 15,\n",
       "         'Cabral': 15,\n",
       "         'fictional': 15,\n",
       "         'positive': 14,\n",
       "         '2014': 14,\n",
       "         'rest': 14,\n",
       "         'growth': 14,\n",
       "         'once': 14,\n",
       "         'numbers': 14,\n",
       "         'woman': 14,\n",
       "         'soldiers': 14,\n",
       "         'list': 14,\n",
       "         'full': 14,\n",
       "         'gave': 14,\n",
       "         'upon': 14,\n",
       "         'According': 14,\n",
       "         'provided': 14,\n",
       "         'announced': 14,\n",
       "         'goals': 14,\n",
       "         'Two': 14,\n",
       "         'U': 14,\n",
       "         'Club': 14,\n",
       "         'instead': 14,\n",
       "         'served': 14,\n",
       "         'hold': 14,\n",
       "         'soon': 14,\n",
       "         'door': 14,\n",
       "         'born': 14,\n",
       "         'finally': 14,\n",
       "         'Croydon': 14,\n",
       "         'School': 14,\n",
       "         'Following': 14,\n",
       "         '24': 14,\n",
       "         'conducted': 14,\n",
       "         'attack': 14,\n",
       "         'taking': 14,\n",
       "         'eight': 14,\n",
       "         'society': 14,\n",
       "         'football': 14,\n",
       "         '1998': 14,\n",
       "         'Another': 14,\n",
       "         'maskray': 14,\n",
       "         'cm': 14,\n",
       "         'together': 14,\n",
       "         'metres': 14,\n",
       "         'result': 14,\n",
       "         'Carey': 14,\n",
       "         'vocals': 14,\n",
       "         'inches': 14,\n",
       "         'water': 14,\n",
       "         'CAT': 14,\n",
       "         'depicted': 14,\n",
       "         'worship': 14,\n",
       "         'la': 14,\n",
       "         'sector': 14,\n",
       "         'airports': 14,\n",
       "         'flights': 14,\n",
       "         'de': 14,\n",
       "         '1849': 14,\n",
       "         'Patterson': 14,\n",
       "         'Feast': 14,\n",
       "         'video': 13,\n",
       "         'black': 13,\n",
       "         'features': 13,\n",
       "         'making': 13,\n",
       "         'praised': 13,\n",
       "         'players': 13,\n",
       "         'help': 13,\n",
       "         'always': 13,\n",
       "         'heavy': 13,\n",
       "         'types': 13,\n",
       "         'young': 13,\n",
       "         'armed': 13,\n",
       "         'despite': 13,\n",
       "         'similar': 13,\n",
       "         'bass': 13,\n",
       "         'review': 13,\n",
       "         'issues': 13,\n",
       "         'television': 13,\n",
       "         '1997': 13,\n",
       "         'newly': 13,\n",
       "         'Civil': 13,\n",
       "         'giving': 13,\n",
       "         'allowed': 13,\n",
       "         '1862': 13,\n",
       "         'attempted': 13,\n",
       "         'naval': 13,\n",
       "         'purposes': 13,\n",
       "         'Christian': 13,\n",
       "         'Book': 13,\n",
       "         'died': 13,\n",
       "         'social': 13,\n",
       "         'wall': 13,\n",
       "         'international': 13,\n",
       "         'Many': 13,\n",
       "         'wide': 13,\n",
       "         'Nash': 13,\n",
       "         'reached': 13,\n",
       "         'debut': 13,\n",
       "         'earlier': 13,\n",
       "         'missing': 13,\n",
       "         'historical': 13,\n",
       "         'Got': 13,\n",
       "         'Way': 13,\n",
       "         'version': 13,\n",
       "         'acting': 13,\n",
       "         'July': 13,\n",
       "         'civil': 13,\n",
       "         'Lightning': 13,\n",
       "         'business': 13,\n",
       "         'groups': 13,\n",
       "         'Other': 13,\n",
       "         'king': 13,\n",
       "         'formation': 13,\n",
       "         'traditional': 13,\n",
       "         'EASA': 13,\n",
       "         'aerodrome': 13,\n",
       "         'airfields': 13,\n",
       "         'Type': 13,\n",
       "         'Palin': 13,\n",
       "         'Emmy': 13,\n",
       "         'portico': 13,\n",
       "         'Nameless': 12,\n",
       "         'nation': 12,\n",
       "         'opening': 12,\n",
       "         'critics': 12,\n",
       "         'missions': 12,\n",
       "         'having': 12,\n",
       "         'very': 12,\n",
       "         'act': 12,\n",
       "         'will': 12,\n",
       "         'does': 12,\n",
       "         'Army': 12,\n",
       "         'foreign': 12,\n",
       "         'works': 12,\n",
       "         'certain': 12,\n",
       "         'proposed': 12,\n",
       "         'beginning': 12,\n",
       "         'thought': 12,\n",
       "         'seven': 12,\n",
       "         'initially': 12,\n",
       "         'available': 12,\n",
       "         'overall': 12,\n",
       "         '500': 12,\n",
       "         'standing': 12,\n",
       "         'good': 12,\n",
       "         'Project': 12,\n",
       "         'eventually': 12,\n",
       "         'remaining': 12,\n",
       "         'commander': 12,\n",
       "         'club': 12,\n",
       "         'construction': 12,\n",
       "         'officers': 12,\n",
       "         'State': 12,\n",
       "         'consisted': 12,\n",
       "         'almost': 12,\n",
       "         'lost': 12,\n",
       "         'strong': 12,\n",
       "         'Confederate': 12,\n",
       "         'placed': 12,\n",
       "         'Records': 12,\n",
       "         'scope': 12,\n",
       "         'shot': 12,\n",
       "         'surrounding': 12,\n",
       "         'significant': 12,\n",
       "         '1911': 12,\n",
       "         'Later': 12,\n",
       "         'designated': 12,\n",
       "         '1923': 12,\n",
       "         'closed': 12,\n",
       "         'planning': 12,\n",
       "         '1961': 12,\n",
       "         '1929': 12,\n",
       "         'Sun': 12,\n",
       "         'initial': 12,\n",
       "         '2002': 12,\n",
       "         'disc': 12,\n",
       "         'Western': 12,\n",
       "         'estimated': 12,\n",
       "         'close': 12,\n",
       "         'region': 12,\n",
       "         'term': 12,\n",
       "         'Northern': 12,\n",
       "         'scoring': 12,\n",
       "         'Penguins': 12,\n",
       "         'might': 12,\n",
       "         'stage': 12,\n",
       "         'observatory': 12,\n",
       "         'subsequently': 12,\n",
       "         'according': 12,\n",
       "         'Be': 12,\n",
       "         'Savannah': 12,\n",
       "         'connected': 12,\n",
       "         'difficult': 12,\n",
       "         'Royal': 12,\n",
       "         'success': 12,\n",
       "         'Award': 12,\n",
       "         'ground': 12,\n",
       "         'e': 12,\n",
       "         'search': 12,\n",
       "         'Awards': 12,\n",
       "         'brother': 12,\n",
       "         're': 12,\n",
       "         'fleet': 12,\n",
       "         'operation': 12,\n",
       "         'goddesses': 12,\n",
       "         'depicts': 12,\n",
       "         'focus': 12,\n",
       "         'states': 12,\n",
       "         'kings': 12,\n",
       "         'example': 12,\n",
       "         'Osiris': 12,\n",
       "         'especially': 12,\n",
       "         'hair': 12,\n",
       "         'America': 12,\n",
       "         'tour': 12,\n",
       "         'European': 12,\n",
       "         'facilities': 12,\n",
       "         'sculpture': 12,\n",
       "         'Corey': 12,\n",
       "         'Chaykovsky': 12,\n",
       "         'Dutch': 12,\n",
       "         'hill': 12,\n",
       "         'approach': 11,\n",
       "         'related': 11,\n",
       "         'movement': 11,\n",
       "         'move': 11,\n",
       "         'entire': 11,\n",
       "         'whose': 11,\n",
       "         'officer': 11,\n",
       "         'towards': 11,\n",
       "         'lives': 11,\n",
       "         'staff': 11,\n",
       "         'wanted': 11,\n",
       "         'come': 11,\n",
       "         'true': 11,\n",
       "         'Its': 11,\n",
       "         'body': 11,\n",
       "         'need': 11,\n",
       "         'instruments': 11,\n",
       "         'working': 11,\n",
       "         'revealed': 11,\n",
       "         'noted': 11,\n",
       "         'non': 11,\n",
       "         'episode': 11,\n",
       "         'planned': 11,\n",
       "         '28': 11,\n",
       "         'my': 11,\n",
       "         'official': 11,\n",
       "         'leaving': 11,\n",
       "         'old': 11,\n",
       "         'turned': 11,\n",
       "         'activity': 11,\n",
       "         'Sanford': 11,\n",
       "         'entrance': 11,\n",
       "         'smaller': 11,\n",
       "         'ones': 11,\n",
       "         'Great': 11,\n",
       "         'Art': 11,\n",
       "         'school': 11,\n",
       "         'critic': 11,\n",
       "         '1918': 11,\n",
       "         'studio': 11,\n",
       "         'study': 11,\n",
       "         'becoming': 11,\n",
       "         'least': 11,\n",
       "         'Hockey': 11,\n",
       "         'alongside': 11,\n",
       "         '50': 11,\n",
       "         'streak': 11,\n",
       "         'tied': 11,\n",
       "         'ever': 11,\n",
       "         'break': 11,\n",
       "         'our': 11,\n",
       "         'Johnson': 11,\n",
       "         '2003': 11,\n",
       "         'observations': 11,\n",
       "         'BC': 11,\n",
       "         'we': 11,\n",
       "         'says': 11,\n",
       "         'Fingal': 11,\n",
       "         'speed': 11,\n",
       "         'controlled': 11,\n",
       "         'cut': 11,\n",
       "         'means': 11,\n",
       "         'Sri': 11,\n",
       "         'Year': 11,\n",
       "         'age': 11,\n",
       "         'relationship': 11,\n",
       "         'date': 11,\n",
       "         'Flying': 11,\n",
       "         'supported': 11,\n",
       "         'East': 11,\n",
       "         'itself': 11,\n",
       "         'far': 11,\n",
       "         'Ancona': 11,\n",
       "         'Allied': 11,\n",
       "         'tradition': 11,\n",
       "         'seated': 11,\n",
       "         'represent': 11,\n",
       "         'physical': 11,\n",
       "         'fully': 11,\n",
       "         'dies': 11,\n",
       "         'saw': 11,\n",
       "         'basic': 11,\n",
       "         'Private': 11,\n",
       "         ...})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_and_preprocess_wikitext(file_path):\n",
    "    # Load the data\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read().splitlines()\n",
    "    # Preprocess: Remove lines that are too short, and tokenize\n",
    "    sentences = [line for line in text if len(line.split()) > 2]\n",
    "    return sentences[:1000]  # Taking only 1000 sentences for simplicity\n",
    "\n",
    "def tokenize(sentence):\n",
    "    \"\"\"Tokenizes a sentence.\"\"\"\n",
    "    return [word for word in re.split(r'\\W+', sentence) if word]\n",
    "\n",
    "def sentence_to_tensor(sentence):\n",
    "    \"\"\"Converts a sentence to its tensor representation.\"\"\"\n",
    "    tokens = tokenize(sentence)\n",
    "    tokens = ['<SOS>'] + tokens + ['<EOS>']\n",
    "    if len(tokens) > MAX_LENGTH:\n",
    "        tokens = tokens[:MAX_LENGTH]\n",
    "    while len(tokens) < MAX_LENGTH:\n",
    "        tokens.append('<PAD>')\n",
    "    tensor = torch.tensor([word2index.get(token, word2index[\"<UNK>\"]) for token in tokens], dtype=torch.long)\n",
    "    return tensor\n",
    "\n",
    "wikitext_train_path = \"wikitext-2/wiki.train.tokens\"  # Modify the path as per your directory structure\n",
    "wikitext_sentences = load_and_preprocess_wikitext(wikitext_train_path)\n",
    "all_words = [word for sentence in wikitext_sentences for word in tokenize(sentence)]\n",
    "vocab = Counter(all_words)\n",
    "vocab\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型参数和词汇表："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 256\n",
    "NUM_HEADS = 4\n",
    "NUM_LAYERS = 2\n",
    "LATENT_DIM = 50\n",
    "MAX_LENGTH = 10  # or whatever maximum length you decide on\n",
    "\n",
    "special_tokens = ['<PAD>', '<SOS>', '<EOS>', '<UNK>']\n",
    "all_tokens = special_tokens + [word for word, _ in vocab.most_common()]\n",
    "word2index = {word: index for index, word in enumerate(all_tokens)}\n",
    "index2word = {index: word for word, index in word2index.items()}\n",
    "VOCAB_SIZE = len(word2index)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerCVAE(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(9694, 256)\n",
       "    (transformer): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fc_mu): Linear(in_features=2304, out_features=50, bias=True)\n",
       "    (fc_var): Linear(in_features=2304, out_features=50, bias=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(9694, 256)\n",
       "    (transformer): Transformer(\n",
       "      (encoder): TransformerEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-1): 2 x TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): TransformerDecoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-1): 2 x TransformerDecoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (multihead_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "            (dropout3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (fc_out): Linear(in_features=256, out_features=9694, bias=True)\n",
       "    (fc_latent_to_embedding): Linear(in_features=50, out_features=2560, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(VOCAB_SIZE, EMBEDDING_DIM)\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(EMBEDDING_DIM, NUM_HEADS),\n",
    "            num_layers=NUM_LAYERS\n",
    "        )\n",
    "        # self.fc_mu = nn.Linear(MAX_LENGTH * EMBEDDING_DIM, LATENT_DIM)\n",
    "        # self.fc_var = nn.Linear(MAX_LENGTH * EMBEDDING_DIM, LATENT_DIM)\n",
    "        self.fc_mu = nn.Linear((MAX_LENGTH-1)*EMBEDDING_DIM, LATENT_DIM)\n",
    "        self.fc_var = nn.Linear((MAX_LENGTH-1)*EMBEDDING_DIM, LATENT_DIM)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, src):\n",
    "        embedded = self.embedding(src)\n",
    "        encoded = self.transformer(embedded)\n",
    "        mu = self.fc_mu(encoded.permute(1, 0, 2).reshape(src.size(0), -1))\n",
    "        logvar = self.fc_var(encoded.permute(1, 0, 2).reshape(src.size(0), -1))\n",
    "        return mu, logvar\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.sequence_length = MAX_LENGTH\n",
    "        self.latent_dim = LATENT_DIM\n",
    "        self.embedding = nn.Embedding(VOCAB_SIZE, EMBEDDING_DIM)\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=EMBEDDING_DIM,\n",
    "            nhead=NUM_HEADS,\n",
    "            num_encoder_layers=NUM_LAYERS,\n",
    "            num_decoder_layers=NUM_LAYERS\n",
    "        )\n",
    "        self.fc_out = nn.Linear(EMBEDDING_DIM, VOCAB_SIZE)\n",
    "        # self.fc_latent_to_embedding = nn.Linear(self.sequence_length * self.latent_dim, MAX_LENGTH * EMBEDDING_DIM)\n",
    "        self.fc_latent_to_embedding = nn.Linear(LATENT_DIM, MAX_LENGTH * EMBEDDING_DIM)\n",
    "\n",
    "\n",
    "    def forward(self, tgt, z):\n",
    "        embedded = self.embedding(tgt)\n",
    "        # Flatten z and then reshape it to the desired shape\n",
    "        z_flattened = z.view(z.size(0), -1)  # Shape: [batch_size, 9*50]\n",
    "        embedded_latent = self.fc_latent_to_embedding(z_flattened)  # Shape: [batch_size, MAX_LENGTH * EMBEDDING_DIM]\n",
    "        embedded_latent = embedded_latent.view(z.size(0), MAX_LENGTH, EMBEDDING_DIM)  # Reshape to [batch_size, MAX_LENGTH, EMBEDDING_DIM]\n",
    "        print(embedded.shape)\n",
    "        print(embedded_latent.shape)\n",
    "        decoded = self.transformer(embedded, embedded_latent)\n",
    "        out = self.fc_out(decoded)\n",
    "        return out\n",
    "\n",
    "\n",
    "class TransformerCVAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TransformerCVAE, self).__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        z = mu + eps * std\n",
    "        return z\n",
    "\n",
    "    def forward(self, src, tgt, tau=1.0):\n",
    "        mu, logvar = self.encoder(src)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        gumbel_softmax_sample = F.gumbel_softmax(z, tau=tau, hard=False)\n",
    "        out = self.decoder(tgt, gumbel_softmax_sample)\n",
    "        return out, mu, logvar\n",
    "\n",
    "\n",
    "# Instantiate the model to check if it's constructed correctly\n",
    "model = TransformerCVAE().to(device)\n",
    "model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练 & 生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1]' is invalid for input of size 50",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 50\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mall\u001b[39m(length \u001b[39m==\u001b[39m \u001b[39m10\u001b[39m \u001b[39mfor\u001b[39;00m length \u001b[39min\u001b[39;00m lengths_updated)\n\u001b[1;32m     49\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m train(model, tensor_data_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n\u001b[1;32m     52\u001b[0m \u001b[39m# Generate a sentence\u001b[39;00m\n\u001b[1;32m     53\u001b[0m generated_sentence \u001b[39m=\u001b[39m generate_sentence(model)\n",
      "Cell \u001b[0;32mIn[5], line 14\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, data, epochs, lr)\u001b[0m\n\u001b[1;32m     11\u001b[0m sentence_in \u001b[39m=\u001b[39m sentence[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[1;32m     12\u001b[0m sentence_out \u001b[39m=\u001b[39m sentence[\u001b[39m1\u001b[39m:]\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m outputs, mu, logvar \u001b[39m=\u001b[39m model(sentence_in, sentence_in)\n\u001b[1;32m     15\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, VOCAB_SIZE), sentence_out\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[1;32m     17\u001b[0m \u001b[39m# Add KL divergence\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/myCVAE/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[4], line 71\u001b[0m, in \u001b[0;36mTransformerCVAE.forward\u001b[0;34m(self, src, tgt, tau)\u001b[0m\n\u001b[1;32m     69\u001b[0m z \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreparameterize(mu, logvar)\n\u001b[1;32m     70\u001b[0m gumbel_softmax_sample \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mgumbel_softmax(z, tau\u001b[39m=\u001b[39mtau, hard\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m---> 71\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(tgt, gumbel_softmax_sample)\n\u001b[1;32m     72\u001b[0m \u001b[39mreturn\u001b[39;00m out, mu, logvar\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/myCVAE/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[4], line 45\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[0;34m(self, tgt, z)\u001b[0m\n\u001b[1;32m     43\u001b[0m embedded \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding(tgt)\n\u001b[1;32m     44\u001b[0m \u001b[39m# Flatten z and then reshape it to the desired shape\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m z_flattened \u001b[39m=\u001b[39m z\u001b[39m.\u001b[39;49mview(z\u001b[39m.\u001b[39;49msize(\u001b[39m0\u001b[39;49m))  \u001b[39m# Shape: [batch_size, 9*50]\u001b[39;00m\n\u001b[1;32m     46\u001b[0m embedded_latent \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc_latent_to_embedding(z_flattened)  \u001b[39m# Shape: [batch_size, MAX_LENGTH * EMBEDDING_DIM]\u001b[39;00m\n\u001b[1;32m     47\u001b[0m embedded_latent \u001b[39m=\u001b[39m embedded_latent\u001b[39m.\u001b[39mview(z\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), MAX_LENGTH, EMBEDDING_DIM)  \u001b[39m# Reshape to [batch_size, MAX_LENGTH, EMBEDDING_DIM]\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[1]' is invalid for input of size 50"
     ]
    }
   ],
   "source": [
    "def train(model, data, epochs=10, lr=0.001):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for sentence in data:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Prepare the input and target tensors\n",
    "            sentence_in = sentence[:-1].unsqueeze(0)\n",
    "            sentence_out = sentence[1:].unsqueeze(0)\n",
    "            \n",
    "            outputs, mu, logvar = model(sentence_in, sentence_in)\n",
    "            loss = criterion(outputs.view(-1, VOCAB_SIZE), sentence_out.view(-1))\n",
    "            \n",
    "            # Add KL divergence\n",
    "            KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "            loss += KLD\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss / len(data)}\")\n",
    "\n",
    "# Now, let's define a function to generate sentences from the trained model\n",
    "def generate_sentence(model, max_length=MAX_LENGTH):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Start with the <SOS> token\n",
    "        sentence = [word2index[\"<SOS>\"]]\n",
    "        for _ in range(max_length - 1):\n",
    "            input_tensor = torch.tensor(sentence).unsqueeze(0)\n",
    "            outputs, _, _ = model(input_tensor, input_tensor)\n",
    "            next_word_idx = torch.argmax(outputs[0, -1]).item()\n",
    "            if next_word_idx == word2index[\"<EOS>\"]:\n",
    "                break\n",
    "            sentence.append(next_word_idx)\n",
    "        return ' '.join([index2word[idx] for idx in sentence])\n",
    "\n",
    "# Convert the wikitext sentences to tensor format for training\n",
    "# tensor_data_train = [sentence_to_tensor(sentence) for sentence in wikitext_sentences]\n",
    "tensor_data_train = [sentence_to_tensor(sentence).to(device) for sentence in wikitext_sentences]\n",
    "# Check the lengths to ensure they are all 10\n",
    "lengths_updated = [len(tensor) for tensor in tensor_data_train]\n",
    "all(length == 10 for length in lengths_updated)\n",
    "\n",
    "# Train the model\n",
    "train(model, tensor_data_train, epochs=5)\n",
    "\n",
    "# Generate a sentence\n",
    "generated_sentence = generate_sentence(model)\n",
    "generated_sentence\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myCVAE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
